<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/next-nest/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/next-nest/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/next-nest/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/next-nest/images/logo.svg" color="#222">

<link rel="stylesheet" href="/next-nest/css/main.css">


<link rel="stylesheet" href="/next-nest/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/next-nest/lib/pace/pace-theme-material.min.css">
  <script src="/next-nest/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"liella-gen2.github.io","root":"/next-nest/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"buttons","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="欲しがったものは全部無くなって消えてくけど生きていく理由は　きっとこれからでも見つかるよ">
<meta property="og:type" content="website">
<meta property="og:title" content="Next Nest">
<meta property="og:url" content="https://liella-gen2.github.io/next-nest/page/5/index.html">
<meta property="og:site_name" content="Next Nest">
<meta property="og:description" content="欲しがったものは全部無くなって消えてくけど生きていく理由は　きっとこれからでも見つかるよ">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="世界ノ敵P">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://liella-gen2.github.io/next-nest/page/5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Next Nest</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="\next-nest\assets\css\APlayer.min.css" class="aplayer-style-marker">
<script src="\next-nest\assets\js\APlayer.min.js" class="aplayer-script-marker"></script>
<script src="\next-nest\assets\js\Meting.min.js" class="meting-script-marker"></script>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/next-nest/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Next Nest</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">wusa!~<code>(•㉨•)</code></p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/next-nest/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/next-nest/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">65</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/next-nest/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">26</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2021/05/09/past_posts/notes/DynamicProgramming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2021/05/09/past_posts/notes/DynamicProgramming/" class="post-title-link" itemprop="url">DynamicProgramming</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-09 15:28:22" itemprop="dateCreated datePublished" datetime="2021-05-09T15:28:22+08:00">2021-05-09</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2021/05/09/past_posts/notes/DynamicProgramming/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2021/05/09/past_posts/notes/DynamicProgramming/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>稍微写一点 <code>dp (Dynamic Programming, 动态规划)</code> 相关的…</p>
<p>说实话，从接触dp的高一上学期，一直到现在写关于dp的大一下学期，这四年从来都没有 真⭐正⭐理⭐解 dp，所以下面只是说一个能做出来dp基础题目的人是如何把那些题目水过去的。</p>
<p>先说说dp的几种基础问题类型：</p>
<ol>
<li><p>最长增减子序贯</p>
<ul>
<li>LIS: Longest Increasing Subsequence, 最长上升子序贯</li>
<li>LDS: Longest Decreasing Subsequence, 最长下降子序贯</li>
</ul>
</li>
<li><p>数字三角形 <code>(USACO1.5)</code> <code>(IOI1994)</code> <a target="_blank" rel="noopener" href="https://www.luogu.com.cn/problem/P1216"><code>(P1216)</code></a></p>
</li>
<li><p>LCS: Longest Common Subsequence, 最长公共子序贯 <a target="_blank" rel="noopener" href="https://www.luogu.com.cn/problem/P1439"><code>(P1439)</code></a></p>
</li>
<li><p>MSA: Maximum SubArray, 最大子段和 <a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/maximum-subarray/"><code>(LC0053)</code></a></p>
</li>
<li><p>打家劫舍系列</p>
<ul>
<li>打家劫舍 <a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/house-robber/"><code>(LC0198)</code></a></li>
<li>按摩师 <a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/the-masseuse-lcci/"><code>(LC面试17-16)</code></a></li>
<li>打家劫舍 II <a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/house-robber-ii/"><code>(LC0213)</code></a></li>
<li>打家劫舍 III <a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/house-robber-iii/"><code>(LC0337)</code></a></li>
</ul>
</li>
</ol>
<h2 id="LDS"><a href="#LDS" class="headerlink" title="LDS"></a>LDS</h2><h2 id="数字三角形"><a href="#数字三角形" class="headerlink" title="数字三角形"></a>数字三角形</h2><blockquote>
<p>观察下面的数字金字塔。</p>
<p>写一个程序来查找从最高点到底部任意处结束的路径，使路径经过数字的和最大。每一步可以走到左下方的点也可以到达右下方的点。</p>
<pre><code>               [7]
              /
           [3]      8 
          /
       [8]      1       0 
          \
    2      [7]      4       4 
          /
4      [5]      2       6       5 
</code></pre><p>在上面的样例中，从 $7 \rightarrow 3 \rightarrow 8 \rightarrow 7 \rightarrow 5$ 的路径产生了最大。</p>
</blockquote>
<h3 id="Other-Info"><a href="#Other-Info" class="headerlink" title="Other Info"></a>Other Info</h3><h4 id="Input-Format"><a href="#Input-Format" class="headerlink" title="Input Format"></a>Input Format</h4><p>第一个行一个正整数 $r$ ，表示行的数目。</p>
<p>后面每行为这个数字金字塔特定行包含的整数。</p>
<h4 id="Output-Format"><a href="#Output-Format" class="headerlink" title="Output Format"></a>Output Format</h4><p>单独的一行，包含那个可能得到的最大的和。</p>
<h4 id="IO-Example"><a href="#IO-Example" class="headerlink" title="IO Example"></a>IO Example</h4><pre><code>In [1]:
5
7
3 8
8 1 0
2 7 4 4
4 5 2 6 5
Out[1]:
30
</code></pre><h4 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h4><p>「数据范围：对于 $100\%$ 的数据， $1 \le r \le 1000$ ，所有输入在 $[0, 100]$ 范围内。</p>
<p>题目翻译来自 NOCOW / USACO Training Section 1.5 / IOI1994 Day1T1</p>
<h3 id="Script"><a href="#Script" class="headerlink" title="Script"></a>Script</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env Python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dp_recursion</span>(<span class="params">k, l</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="built_in">max</span>(dp_recursion(k + <span class="number">1</span>, l), dp_recursion(k + <span class="number">1</span>, l + <span class="number">1</span>)) + arr[k, l]) <span class="keyword">if</span> k &lt; r <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    r = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">    arr = np.zeros((r, r))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(r):</span><br><span class="line">        arr[ k , : (k + <span class="number">1</span>) ] += [ <span class="built_in">int</span>(each) <span class="keyword">for</span> each <span class="keyword">in</span> <span class="built_in">input</span>().split() ]</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">int</span>(dp_recursion(<span class="number">0</span>, <span class="number">0</span>)))</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2021/05/09/past_posts/notes/MathJax/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2021/05/09/past_posts/notes/MathJax/" class="post-title-link" itemprop="url">MathJax 骚操作整理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-09 00:21:12" itemprop="dateCreated datePublished" datetime="2021-05-09T00:21:12+08:00">2021-05-09</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2021/05/09/past_posts/notes/MathJax/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2021/05/09/past_posts/notes/MathJax/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="花体字符"><a href="#花体字符" class="headerlink" title="花体字符"></a>花体字符</h2><p>以</p>
<pre><code>Awesome Hatsune MIKU desu !!!
</code></pre><p>为例。</p>
<ul>
<li><p>Cal (常规花体)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ \mathcal&#123;Awesome Hatsune MIKU desu !!!&#125; $$</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">\mathcal{Awesome Hatsune MIKU desu !!!}</script></li>
<li><p><strong>Scr (（伪）手写体，常见于线性变换)</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ \mathscr&#123;Awesome Hatsune MIKU desu !!!&#125; $$</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">\mathscr{Awesome Hatsune MIKU desu !!!}</script></li>
<li><p>Bb (黑板粗体，常见于数域的表达)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ \mathbb&#123;Awesome Hatsune MIKU desu !!!&#125; $$</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">\mathbb{Awesome Hatsune MIKU desu !!!}</script></li>
<li><p>Bf (常规粗体)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ \mathbf&#123;Awesome Hatsune MIKU desu !!!&#125; $$</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">\mathbf{Awesome Hatsune MIKU desu !!!}</script></li>
<li><p>Sf (等线体)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ \mathsf&#123;Awesome Hatsune MIKU desu !!!&#125; $$</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">\mathsf{Awesome Hatsune MIKU desu !!!}</script></li>
<li><p>Frak (旧德式体，正常人看不清楚，慎用！)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ \mathfrak&#123;Awesome Hatsune MIKU desu !!!&#125; $$</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">\mathfrak{Awesome Hatsune MIKU desu !!!}</script></li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>[1]: <a target="_blank" rel="noopener" href="https://blog.csdn.net/liyuanbhu/article/details/51474533/">https://blog.csdn.net/liyuanbhu/article/details/51474533/</a></li>
<li>[2]: <a target="_blank" rel="noopener" href="https://heartlessly.github.io/others/latex-mathjax-gong-shi-zi-ti-mei-hua/">https://heartlessly.github.io/others/latex-mathjax-gong-shi-zi-ti-mei-hua/</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2021/05/05/past_posts/essays/2021-0505/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2021/05/05/past_posts/essays/2021-0505/" class="post-title-link" itemprop="url">日志#2021-0505 写在 51mcm 之后：最终发现无需追忆昨天</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-05 15:30:41" itemprop="dateCreated datePublished" datetime="2021-05-05T15:30:41+08:00">2021-05-05</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2021/05/05/past_posts/essays/2021-0505/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2021/05/05/past_posts/essays/2021-0505/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote><p><img src="/next-nest/2021/05/05/past_posts/essays/2021-0505/稻荷崎.jpeg" alt="稻荷崎"></p>
<hr>
<p style="text-align: center; display: none;">
  <ruby><span>思い出</span><rp>(</rp><rt>无需</rt><rp>)</rp></ruby>
  <ruby><span>なんか</span><rp>(</rp><rt>追忆</rt><rp>)</rp></ruby>
  <ruby><span>いらん</span><rp>(</rp><rt>昨天</rt><rp>)</rp></ruby>
</p>

<p class="h1" style="text-align: center;">
  <ruby>思い出なんかいらん<rp>(</rp><rt>无需追忆昨天</rt><rp>)</rp></ruby>
</p>
<footer><strong>兵库县代表——稻荷崎高中男子排球部赛场横幅</strong><cite>古馆春一作品「ハイキュー！！」（排球少年！！）</cite></footer></blockquote>
<h3 id="2021年5月5日"><a href="#2021年5月5日" class="headerlink" title="2021年5月5日"></a>2021年5月5日</h3><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>大概是这次的劳动节兼青年节假期，我与计划于秋天一起参加<a target="_blank" rel="noopener" href="http://www.mcm.edu.cn/"><code>cumcm</code></a>的前辈们参加了<a target="_blank" rel="noopener" href="http://51mcm.cumt.edu.cn/"><code>51mcm</code></a>，是中国矿业大学组织的数学建模竞赛。我们所选的题目，是关于运筹与规划的题目A，疫苗生产问题：</p>
<blockquote>
<p>新冠肺炎肆虐全球，给世界带来了深重的灾难。各国为控制疫情纷纷研发新冠疫苗。假定疫苗生产需要经过 $CJ_1$ 工位、 $CJ_2$ 工位、 $CJ_3$ 工位以及 $CJ_4$ 工位等4个工艺流程。每个工艺流程一次性均能处理100剂疫苗，这100剂疫苗装进一个加工箱一起送进工位的设备进行处理。而且，只有按照 $CJ_1 \rightarrow CJ_2 \rightarrow CJ_3 \rightarrow CJ_4$ 的顺序在4个工位都进行了加工以后，才算完成生产。为防止疫苗包装出现混乱，某疫苗生产公司生产部门规定，每个工位不能同时生产不同类型的疫苗，疫苗生产不允许插队，即进入第一个工位安排的每类疫苗的生产顺序一旦确定就要一直保持不变，而且前一种类型的疫苗离开某个工位后，后一种类型的疫苗才能进入这个工位。</p>
<p>现有 $YM_1$ 至 $YM_{10} $ 等10种不同类型的疫苗需要生产。为安全起见，每种类型每箱（内装疫苗100剂）疫苗在每个工位上均进行了50次模拟生产。发现，由于生产设备、疫苗纯化等多种原因，每个工位生产不同类型的每箱疫苗所需的时间并不稳定，详细的数据见附件1。</p>
<p>T1: 请对每箱疫苗在所有工位上的生产时间进行均值、方差、最值、概率分布等统计分析，以方便疫苗生产公司管理者能够直观的掌握每个工位生产疫苗的能力水平，为疫苗生产提供参考。</p>
<p>T2: 某国疫苗检测部门紧急需要 $YM_1 \rightarrow YM_{10} $ 各100剂疫苗进行检测。为赶时间，疫苗生产公司需要对疫苗的生产顺序进行规划，以便能在最短时间内交付，以每个工位生产每箱疫苗平均时间为依据。请建立数学模型，制定疫苗生产顺序，初始时刻为00:00，计算生产总时间<del>，并将结果填入表1</del>。<br>…</p>
</blockquote>

    <div id="aplayer-RbBRchHU" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="518426" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#ad7a86"></div>
<h2 id="Model-Building-模型构建"><a href="#Model-Building-模型构建" class="headerlink" title="Model Building (模型构建)"></a>Model Building (模型构建)</h2><p>在<code>pandas</code>库的帮助下，T1我们几乎是秒杀的，顺便完成了所有数据的初步清洗与预处理。但是我们来到T2时便遇上了麻烦。</p>
<p>面对T2我们首先想到的是<a target="_blank" rel="noopener" href="https://blog.csdn.net/a493823882/article/details/78209512/">排队论</a>，但在梳理了排队论的基本方法与使用情况之后，转而想到<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/动态规划/529408">dp (Dynamic Programming, 动态规划)</a>，但奈何状态转移方程死活写不出来，最终放弃了dp，决定沿用前人的「零件加工」思路：</p>
<p>设疫苗 $YM_k$ 在工位 $l$ 加工所需时间为 $t_{k, l} $ ，从加工系统开始运作直到疫苗 $YM_k$ 在工位 $CJ_l$ 加工<strong>完成</strong>所需时间为 $s_{k, l} $ ，如若预先指定加工顺序，则进入加工的第 $k$ 类疫苗在工位 $CJ_l$ 加工所需时间设为 $\tau_{k, l} $ ，其在工位 $l$ 加工<strong>完成</strong>所需时间设为 $\sigma_{k, l} $。</p>
<ol>
<li><p>指定顺序的方式有 $A_{10}^{10} = 10!$ 种，可以在原本的类型编号与指定顺序之间建立在数集 $\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$ 上的 <ruby>映<rp>(</rp><rt>一一</rt><rp>)</rp>射<rp>(</rp><rt>对应</rt><rp>)</rp></ruby> 关系 $k^{(1)} = \phi(k)$ ，满足</p>
<script type="math/tex; mode=display">t_{\phi(k), l} = \tau  _{k, l}</script><script type="math/tex; mode=display">s_{\phi(k), l} = \sigma_{k, l}</script></li>
<li><p>考虑指定顺序后的加工过程：工位 $CJ_1$ 中上一类进行加工的疫苗在完成加工后，紧接着可以安排下一类疫苗进入该工位进行加工，由此可知进入加工的第 $k$ 类疫苗完成在工位 $CJ_1$ 加工<strong>完成</strong>所需时间为</p>
<script type="math/tex; mode=display">\sigma_{k, 1} = \sigma_{(k - 1), 1} + \tau_{k, 1}</script></li>
<li><p>而对于在工位 $CJ_2$ 上的疫苗进行加工的情况而言，需要分情况讨论：</p>
<ul>
<li><p>$ \sigma_{k, 1} &lt; \sigma_{(k - 1), 2} $<br>此时第 $k$ 类疫苗需等待至第 $(k - 1)$ 类疫苗在工位 $CJ_2$ 加工完成之后，方能进入该工位开始加工，因此再考虑其在工位 $CJ_2$ 上进行加工所需时间，第 $k$ 类疫苗在工位 $CJ_2$ <strong>完成</strong>加工所需时间</p>
<script type="math/tex; mode=display">\sigma_{k, 2} = \sigma_{(k - 1), 2} + \tau_{k, 2}</script></li>
<li><p>$ otherwise $<br>此时第 $k$ 类疫苗无需等待即可直接进入工位 $CJ_2$ 进行加工，因此其在工位 $CJ_2$ <strong>完成</strong>加工所需时间</p>
<script type="math/tex; mode=display">\sigma_{k, 2} = \sigma_{k, 1}       + \tau_{k, 2}</script></li>
</ul>
<p>综上所述，第 $k$ 类疫苗在工位 $CJ_2$ <strong>完成</strong>加工所需时间</p>
<script type="math/tex; mode=display">\sigma_{k, 2} = max\{ \sigma_{(k - 1), 2}, \sigma_{k, 1} \} + \tau_{k, 2}</script></li>
<li><p>同理，对于在工位 $CJ_3$ 与 $CJ_4$ 的疫苗，完成加工所需时间分别为</p>
<script type="math/tex; mode=display">
   \sigma_{k, 3} = max\{ \sigma_{(k - 1), 3}, \sigma_{k, 2} \} + \tau_{k, 3}
   \\
   \sigma_{k, 4} = max\{ \sigma_{(k - 1), 4}, \sigma_{k, 3} \} + \tau_{k, 4}</script></li>
<li><p>由此，如若我们 <ruby>定<rp>(</rp><rt>强行</rt><rp>)</rp>义<rp>(</rp><rt>规定</rt><rp>)</rp></ruby> 索引为零的情况：</p>
<script type="math/tex; mode=display">k = 0 时, \phi(0) = 0, 且满足
   \\
   t_{0, l} = \tau  _{0, l} \equiv 0
   \\
   s_{0, l} = \sigma_{0, l} \equiv 0</script><p>根据题意，所有疫苗在进入加工前所占用时间不在题目的考虑范围之内，因此 $\forall k \in \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$ 有</p>
<script type="math/tex; mode=display">
   s_{k, 0} \equiv 0
   \\
   \sigma_{k, 0} = s_{\phi(k), 0} \equiv 0</script></li>
<li><p>在上一步的简化下，加工过程中所有时间的计算可以简化为</p>
<script type="math/tex; mode=display">\sigma_{k, l} = max\{ \sigma_{(k - 1), l}, \sigma_{k, (l - 1)} \} + \tau_{k, l}</script></li>
</ol>
<p>经过以上各步，最后一类（即第十类）在最后的工位 $CJ_4$ <strong>完成</strong>加工所需时间 $\sigma_{10, 4} $ 即为我们所求的加工所用的总时间。</p>
<h2 id="Programming-程式编写"><a href="#Programming-程式编写" class="headerlink" title="Programming (程式编写)"></a>Programming (程式编写)</h2><p>进入加工的第 $k$ 类疫苗在工位 $CJ_l$ 加工时间（即上文定义的 $\tau_{k, l} $ ）设为变量<code>producing_time[k, l]</code>，在工位 $CJ_l$ 加工完成所需时间设为递归函数<code>processing_time(k, l)</code>，则上述过程用程式表述如下</p>
<figure class="highlight py"><figcaption><span>proctime.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">processing_time</span>(<span class="params">k = <span class="number">10</span>, l = <span class="number">4</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="built_in">max</span>(processing_time(k - <span class="number">1</span>, l), processing_time(k, l - <span class="number">1</span>)) + producing_time[k, l]) <span class="keyword">if</span> (k <span class="keyword">and</span> l) <span class="keyword">else</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>正如上文所说，共有 $10!$ 种排列方法，我们在此回给出的解决方案便是枚举这 $10!$ 种排列方法。</p>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>参考文献：</p>
<ul>
<li>[1]: <a target="_blank" rel="noopener" href="https://blog.csdn.net/a493823882/article/details/78209512/">https://blog.csdn.net/a493823882/article/details/78209512/</a></li>
<li>[2]: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/291280715/answer/1492289717">https://www.zhihu.com/question/291280715/answer/1492289717</a></li>
<li>[3]: <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23995189/answer/613096905">https://www.zhihu.com/question/23995189/answer/613096905</a></li>
<li>[4]: <a target="_blank" rel="noopener" href="https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie">https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie</a></li>
<li>[5]: <a target="_blank" rel="noopener" href="https://blog.csdn.net/sunyueqinghit/article/details/81562138/">https://blog.csdn.net/sunyueqinghit/article/details/81562138/</a></li>
<li>[6]: <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/动态规划/529408">https://baike.baidu.com/item/动态规划/529408</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2020/11/06/past_posts/essays/2020-1106/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2020/11/06/past_posts/essays/2020-1106/" class="post-title-link" itemprop="url">日志#2020-1106 写在第一次成功击穿次元壁之后</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-11-06 09:02:16" itemprop="dateCreated datePublished" datetime="2020-11-06T09:02:16+08:00">2020-11-06</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2020/11/06/past_posts/essays/2020-1106/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2020/11/06/past_posts/essays/2020-1106/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Whereof whats past <span class="keyword">is</span> prologue, what to come <span class="keyword">in</span> yours <span class="keyword">and</span> my discharge.</span><br></pre></td></tr></table></figure>
<p>凡此过往，皆为序章。（前方未知的未来，由你我的双手铺就。）</p>
<footer><strong>William Shakespeare</strong><cite>the Tempest</cite></footer></blockquote>
<h3 id="2020年11月6日"><a href="#2020年11月6日" class="headerlink" title="2020年11月6日"></a>2020年11月6日</h3><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>前段时间承蒙导师信任，被安排前去参加曾经梦寐以求的数据科学界的<a target="_blank" rel="noopener" href="https://kaggle.com/">Kaggle</a>竞赛，根据队中哥哥姐姐们的兴趣与他们选定了<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/titanic/">Titanic</a>与<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/digit-recognizer/">MNIST</a>两道题目，<del>虽然做的工作很少，但也算是为这两道（大水）题处心积虑煞费苦心</del>。</p>
<p>虽由于网络原因尚未提交submission，但这两个project的<code>accuracy</code>已经达到预期目标，可以告一段落。</p>
<p>而在后面，还有我们最终要做的<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/gan-getting-started/">基于<code>GAN</code>生成Monet作品</a>一项，目前征程尚未结束，我还需要继续努力。<del>（但是现在来考虑，至于还要不要做那道题目，可能是未知数，因为我们可能会换作进行别的project）</del></p>
<p><del>(最近要复习数学和代数的期中考试，因此一直没有整理这一块的内容QAQ)</del></p>

    <div id="aplayer-ANlFuEdb" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="1294899575" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#ad7a86"></div>
<h2 id="基于VGG19与L-BFGS-B优化算法的NST-Neural-Style-Transfer-神经样式迁移"><a href="#基于VGG19与L-BFGS-B优化算法的NST-Neural-Style-Transfer-神经样式迁移" class="headerlink" title="基于VGG19与L-BFGS-B优化算法的NST(Neural Style Transfer, 神经样式迁移)"></a>基于<code>VGG19</code>与<code>L-BFGS-B</code>优化算法的NST(Neural Style Transfer, 神经样式迁移)</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>这个project最早是2018年年底在Keras之父所著的《Deep Learning with Python》上关于生成式深度学习一部分看到的，NST这个算法经常被与DeepDream算法一并提起，后者DeepDream是向给定的现实图像注入细节以生成魔幻（非）现实主义的“梦境”图像。</p>
<p>但我们今天讨论的重点在于前者亦即神经样式迁移，这是由Leon A. Gatys, Alexander S. Ecker, Matthias Bethge三人于文献《A Neural Algorithm of Artistic Style》提出的，与DeepDream拥有诸多相同之处。</p>
<p>其目标在于改变现实图像的细节，以使生成图像具备参考图像的画风，例如使一张现实中的青岛市中山路街道夜景变得像梵高画出来的一样，在像这样的过程之中便可以参考梵高的的《Starry Night》以进行变换。</p>
<p>下面这幅图生动传神地刻画了现实图像被注入目标风格的过程<del>(，虽说操作的对象并不是中山路街道夜景就是啦)</del></p>
<p><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/nst_overview.jpeg" alt="Neural Style Transfer"></p>
<blockquote>
<p>Keywords:</p>
<ul>
<li>Neural Style Transfer (NST)</li>
<li>VGG19</li>
<li>Gram Matrix</li>
<li>L-BFGS-B</li>
</ul>
<p>…</p>
</blockquote>
<h3 id="Loss-Functions"><a href="#Loss-Functions" class="headerlink" title="Loss Functions"></a>Loss Functions</h3><p>作为文献作者的Gatys认为在convnet之中图像的<code>内容</code>与<code>样式</code>被在后面的层中分立表示，例如Gatys老哥用的VGG19中，最后一个block倒数第三个卷积层(即<code>block5_conv2</code>)被用于表示进入convnet被处理的现实图像的内容，而每一个block的第一个卷积层(<code>block1_conv1</code>，<code>block2_conv1</code>…一直到<code>block5_conv1</code>都是)皆被用于表示进入convnet被处理的现实图像的样式。</p>
<p>用convnet中不同的层的隐层输出表示内容和样式之后，可以定义相应的内容损失<code>content_loss</code>和样式损失<code>style_loss</code>，内容损失很好理解其实就是生成图像与现实图像的特征图之间的差量再平方，这就比较类似于我们所熟悉的mse，如若是绝对值的话(我觉得可能)也可以，就比较类似于mae。</p>
<p>与内容损失不同，样式损失通过一个叫做<a target="_blank" rel="noopener" href="https://planetmath.org/grammatrix">Gram Matrix</a>的东西来进行刻画：</p>
<script type="math/tex; mode=display">G_{i,j}^l = F_{i,k}^l \cdot F_{j,k}^l</script><script type="math/tex; mode=display">\Delta(\alpha_1, \alpha_2, \dots, \alpha_k)

= A^T A

= \begin{bmatrix} \alpha_1^T \\ \alpha_2^T \\ \vdots \\ \alpha_k^T \end{bmatrix} \cdot (\alpha_1, \alpha_2, \cdots, \alpha_k)

= \begin{bmatrix}
\alpha_1^T \alpha_1 & \alpha_1^T \alpha_2 & \cdots & \alpha_1^T \alpha_k \\
\alpha_2^T \alpha_1 & \alpha_2^T \alpha_2 & \cdots & \alpha_2^T \alpha_k \\
\vdots              & \vdots              & \ddots & \vdots              \\
\alpha_k^T \alpha_1 & \alpha_k^T \alpha_2 & \cdots & \alpha_k^T \alpha_k \\
\end{bmatrix}</script><p>或是千言万语不及一幅图？</p>
<p><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/grammat.jpeg" alt="Gram Matrix"></p>
<p>所以我们可以从公式或者图看出，这个Gram Matrix实质上就是把矩阵视为一个矢量组，让矢量组之间互相点积得到的结果，所以能够反映出矩阵内部矢量与矢量之间的<strong>自相关性</strong>。这样的相关性从convnet较高层一直保留到较低层，从而保留的是样式。特征相互关系捕捉到的是纹理(texture)，生成图像和参考图像纵使在不同的空间尺度上亦应当具有相同的纹理。</p>
<p>除内容与样式之外，我们还要考虑生成图像的连贯性或者说连续性，以避免生成的结果过度像素化以至于令人感到非常违和，因此Gatys老哥还定义了总变差损失<code>total_variation_loss</code>，简单地说就是：</p>
<blockquote>
<p>(这个project在梯度下降过程之前用到的只是一些简单的对张量的数值代数处理，因此我们</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> keras, keras.backend <span class="keyword">as</span> T</span><br></pre></td></tr></table></figure>
<p>)</p>
</blockquote>
<figure class="highlight py"><figcaption><span>Total Variation Loss</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_variation_loss</span>(<span class="params">x</span>):</span></span><br><span class="line">    a = T.square(</span><br><span class="line">        x[ : , : (img_height - <span class="number">1</span>) , : (img_width - <span class="number">1</span>) , : ] -</span><br><span class="line">        x[ : , <span class="number">1</span> :                , : (img_width - <span class="number">1</span>) , : ]</span><br><span class="line">        )</span><br><span class="line">    b = T.square(</span><br><span class="line">        x[ : , : (img_height - <span class="number">1</span>) , : (img_width - <span class="number">1</span>) , : ] -</span><br><span class="line">        x[ : , : (img_height - <span class="number">1</span>) , <span class="number">1</span> :               , : ]</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> T.<span class="built_in">sum</span>(T.<span class="built_in">pow</span>(a + b, <span class="number">1.25</span>))</span><br></pre></td></tr></table></figure>
<p>对生成图像取了从左上角到倒数第二列倒数第二行的窗口，分别与窗口向右、向下平移一格的窗口作差。这个新定义的损失与我们见过的各种损失同样不可能为零，毕竟除了纯色图之外不可能所有的点与其相邻的点颜色一模一样。明确了三类需要的损失之后，最终需要优化的损失便是三者之和：</p>
<script type="math/tex; mode=display">Loss = Loss_{content} + \sum Loss_{style} + Loss_{variation}</script><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>采用<code>L-BFGS-B</code>算法进行优化，<code>BFGS</code>算法是由Broyden, Fletcher, Goldfarb, Shanno四名科学家提出的优化牛顿迭代法的产物，其改进版<code>L-BFGS</code>算法中的L指代<code>limited_memory</code>即对内存的限制，而再次改进的<code>L-BFGS-B</code>算法中的B指代<code>bound</code>即进一步使<code>L-BFGS</code>支持了极小化过程中对变量施加约束。总的来说这一套发展路程差不多就是<code>Newton -&gt; BFGS -&gt; L-BFGS -&gt; L-BFGS-B</code>，而牛顿迭代法可以通过下方的动图加以理解：</p>
<p><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/newton.gif" alt="Newton Iteration"></p>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>最后我们放一下代码：</p>
<figure class="highlight py"><figcaption><span>Neural Style Transfer</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env Python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">TensorFlow version: 1.11.0</span></span><br><span class="line"><span class="string">Keras version: 2.1.6</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> vgg19</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> T</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> optimize, misc</span><br><span class="line"><span class="keyword">import</span> time, os</span><br><span class="line"></span><br><span class="line"><span class="comment"># Constants</span></span><br><span class="line"></span><br><span class="line">TARGET_IMAGE_PATH = <span class="string">&quot;./images/target.jpeg&quot;</span></span><br><span class="line">REFERENCE_IMAGE_PATH = <span class="string">&quot;./images/amaterasu.jpeg&quot;</span></span><br><span class="line"></span><br><span class="line">WIDTH, HEIGHT = image.load_img(TARGET_IMAGE_PATH).size</span><br><span class="line">IMG_HEIGHT = <span class="number">508</span></span><br><span class="line">IMG_WIDTH = <span class="number">904</span> <span class="comment"># int(WIDTH * IMG_HEIGHT / HEIGHT)</span></span><br><span class="line"></span><br><span class="line">VGG19_MEAN_RGB = [ <span class="number">103.939</span>, <span class="number">116.779</span>, <span class="number">123.680</span> ]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tool Functions</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocessing_image</span>(<span class="params">image_path</span>):</span></span><br><span class="line">    img = image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))</span><br><span class="line">    img = image.img_to_array(img)</span><br><span class="line">    img = np.expand_dims(img, axis=<span class="number">0</span>)</span><br><span class="line">    img = vgg19.preprocess_input(img)</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    or process like this:</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; img = keras_applications.vgg19.preprocess_input(img, backend=keras.backend)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deprocess_image</span>(<span class="params">x</span>):</span></span><br><span class="line">    x[ : , : ] += VGG19_MEAN_RGB</span><br><span class="line">    x = x[ : , : , : : (-<span class="number">1</span>) ]</span><br><span class="line">    x = np.clip(x, <span class="number">0</span>, <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocessing</span></span><br><span class="line"></span><br><span class="line">target_image = preprocessing_image(TARGET_IMAGE_PATH)</span><br><span class="line">target_image = T.constant(target_image)</span><br><span class="line">reference_image = preprocessing_image(REFERENCE_IMAGE_PATH)</span><br><span class="line">reference_image = T.constant(reference_image)</span><br><span class="line">combination_image = T.placeholder([ <span class="number">1</span>, IMG_HEIGHT, IMG_WIDTH, <span class="number">3</span> ])</span><br><span class="line"></span><br><span class="line">input_tensor = T.concatenate([ target_image, reference_image, combination_image ], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">model = vgg19.VGG19(<span class="literal">False</span>, <span class="string">&quot;imagenet&quot;</span>, input_tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;VGG19 model loaded.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">content_loss</span>(<span class="params">base, combination</span>):</span></span><br><span class="line">    <span class="keyword">return</span> T.<span class="built_in">sum</span>(T.square(combination - base))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span>(<span class="params">x</span>):</span></span><br><span class="line">    features = T.batch_flatten(T.permute_dimensions(x, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)))</span><br><span class="line">    gram = T.dot(features, T.transpose(features))</span><br><span class="line">    <span class="keyword">return</span> gram</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_loss</span>(<span class="params">style, combination</span>):</span></span><br><span class="line">    S = gram_matrix(style)</span><br><span class="line">    C = gram_matrix(combination)</span><br><span class="line">    channels = <span class="number">3</span></span><br><span class="line">    size = IMG_HEIGHT * IMG_WIDTH</span><br><span class="line">    <span class="keyword">return</span> T.<span class="built_in">sum</span>(T.square(S - C)) / (<span class="number">4.</span> * (channels ** <span class="number">2</span>) * (size ** <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_variation_loss</span>(<span class="params">x</span>):</span></span><br><span class="line">    a = T.square(x[ : , : (IMG_HEIGHT - <span class="number">1</span>) , : (IMG_WIDTH - <span class="number">1</span>) , : ] - x[ : , <span class="number">1</span> : , : (IMG_WIDTH - <span class="number">1</span>) , : ])</span><br><span class="line">    b = T.square(x[ : , : (IMG_HEIGHT - <span class="number">1</span>) , : (IMG_WIDTH - <span class="number">1</span>) , : ] - x[ : , : (IMG_HEIGHT - <span class="number">1</span>) , <span class="number">1</span> : , : ])</span><br><span class="line">    <span class="keyword">return</span> T.<span class="built_in">sum</span>(T.<span class="built_in">pow</span>(a + b, <span class="number">1.25</span>))</span><br><span class="line"></span><br><span class="line">outputs_dict = <span class="built_in">dict</span>([ (layer.name, layer.output) <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers ])</span><br><span class="line"></span><br><span class="line">CONTENT_LAYER = <span class="string">&quot;block5_conv2&quot;</span></span><br><span class="line">STYLE_LAYERS = [<span class="string">&quot;block1_conv1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;block2_conv1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;block3_conv1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;block4_conv1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;block5_conv1&quot;</span>]</span><br><span class="line"></span><br><span class="line">TOTAL_VARIATION_WEIGHT = <span class="number">1e-04</span></span><br><span class="line">STYLE_WEIGHT = <span class="number">1.</span></span><br><span class="line">CONTENT_WEIGHT = <span class="number">.025</span></span><br><span class="line"></span><br><span class="line">loss = T.variable(<span class="number">0.</span>)</span><br><span class="line">layer_features = outputs_dict[CONTENT_LAYER]</span><br><span class="line">target_image_features = layer_features[ <span class="number">0</span> , : , : , : ]</span><br><span class="line">combination_features = layer_features[ <span class="number">2</span> , : , : , : ]</span><br><span class="line"></span><br><span class="line">loss = loss + content_loss(target_image_features, combination_features)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer_name <span class="keyword">in</span> STYLE_LAYERS:</span><br><span class="line">    layer_features = outputs_dict[layer_name]</span><br><span class="line">    reference_features = layer_features[ <span class="number">1</span> , : , : , : ]</span><br><span class="line">    combination_features = layer_features[ <span class="number">2</span> , : , : , : ]</span><br><span class="line">    sl = style_loss(reference_features, combination_features)</span><br><span class="line">    loss = loss + (STYLE_WEIGHT / <span class="built_in">len</span>(STYLE_LAYERS)) * sl</span><br><span class="line"></span><br><span class="line">loss = loss + TOTAL_VARIATION_WEIGHT * total_variation_loss(combination_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># grads</span></span><br><span class="line"></span><br><span class="line">grads = T.gradients(loss, combination_image)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">fetch_loss_and_grads = T.function([combination_image], [loss, grads])</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Evaluator</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.loss_value = <span class="literal">None</span></span><br><span class="line">        self.grad_values = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> self.loss_value <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line">        x = x.reshape([ <span class="number">1</span>, IMG_HEIGHT, IMG_WIDTH, <span class="number">3</span> ])</span><br><span class="line">        outs = fetch_loss_and_grads([x])</span><br><span class="line">        loss_value = outs[<span class="number">0</span>]</span><br><span class="line">        grad_values = outs[<span class="number">1</span>].flatten().astype(<span class="string">&quot;float64&quot;</span>)</span><br><span class="line">        self.loss_value = loss_value</span><br><span class="line">        self.grad_values = grad_values</span><br><span class="line">        <span class="keyword">return</span> self.loss_value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">grads</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="keyword">not</span>(self.loss_value <span class="keyword">is</span> <span class="literal">None</span>)</span><br><span class="line">        grad_values = np.copy(self.grad_values)</span><br><span class="line">        self.loss_value = <span class="literal">None</span></span><br><span class="line">        self.grad_values = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> grad_values</span><br><span class="line"></span><br><span class="line">evaluator = Evaluator()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Evaluator loaded!&quot;</span>)</span><br><span class="line"></span><br><span class="line">RESULT_PREFIX = <span class="string">&quot;result&quot;</span></span><br><span class="line">NUM_ITERATIONS = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">x = preprocessing_image(TARGET_IMAGE_PATH)</span><br><span class="line">x = x.flatten()</span><br><span class="line"></span><br><span class="line">SAVE_DIR = <span class="string">&quot;results.%s&quot;</span> % time.time()</span><br><span class="line">os.system(<span class="string">&quot;mkdir %s&quot;</span> % SAVE_DIR)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx_iteration <span class="keyword">in</span> <span class="built_in">range</span>(NUM_ITERATIONS):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Iteration %s:&quot;</span> % idx_iteration)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    x, min_val, info = optimize.fmin_l_bfgs_b(evaluator.loss, x, fprime=evaluator.grads, maxfun=<span class="number">20</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Current loss value: %s&quot;</span> % min_val)</span><br><span class="line">    img = x.copy().reshape([ IMG_HEIGHT, IMG_WIDTH, <span class="number">3</span> ])</span><br><span class="line">    img = deprocess_image(img)</span><br><span class="line">    misc.imsave(<span class="string">&quot;./%s/iter_%d.jpeg&quot;</span> % (SAVE_DIR, idx_iteration), img)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Current image saved!&quot;</span>)</span><br><span class="line">    end_time = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Iteration completed in %dsec!&quot;</span> % (end_time - start_time))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><!--p>
  <img id="RawTarget-and-NSTResults" src="raw_target.jpeg" alt="Target" />
  <script>
    $(document).ready(function () {
      $("#RawTarget-and-NSTResults").click(function () {
        if ($("#RawTarget-and-NSTResults").attr("alt") == "Target") {
          $("#RawTarget-and-NSTResults").attr("alt", "Results");
          $("#RawTarget-and-NSTResults").attr("src", "/2020/11/06/notes/2020-1106/nst_results.gif");
        } else {
          $("#RawTarget-and-NSTResults").attr("alt", "Target");
          $("#RawTarget-and-NSTResults").attr("src", "/2020/11/06/notes/2020-1106/raw_target.jpeg");
        }
      });
    });
  </script>
</p-->
<p><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/raw_target.jpeg" alt="Target"><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/nst_results.gif" alt="Results"></p>
<p>在2018年年底看到之后我于2019年1月28日进行第一次实验，但是第一次实验的结果非常不尽人意，现在回想原因大致是设反了参数，于是得到了一个横版图像被挤压为竖版的效果：<img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/nst_result_atiter_0_20190128.jpeg" alt="Failure on 28 Jan 2019"></p>
<p>这个project持续了将近两年，期间因高考而鸽置，然而在将近两年之后的某一个平凡无奇的清晨，终于得到了结果：<img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/nst_result_20201113.jpeg" alt="Result on 13 Nov 2020"></p>
<h2 id="基于VAE-Variational-AutoEncoder-变分自编码机-的手写数字图片-MNIST-潜在连续空间生成"><a href="#基于VAE-Variational-AutoEncoder-变分自编码机-的手写数字图片-MNIST-潜在连续空间生成" class="headerlink" title="基于VAE(Variational AutoEncoder, 变分自编码机)的手写数字图片(MNIST)潜在连续空间生成"></a>基于VAE(Variational AutoEncoder, 变分自编码机)的手写数字图片(MNIST)潜在连续空间生成</h2><h3 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h3><p>这个project最早是2019年年初在Keras之父所著的《Deep Learning with Python》上关于生成式深度学习一部分看到的。VAE的原型，AutoEncoder即自编码机，经常被与GAN(Generative Adversarial Networks, 生成对抗网络)一并提起，因为两者皆是兼具类似于生成与类似于预测两套模型的组合。</p>
<p>但是AutoEncoder为<code>Encoder</code>(编码机)和<code>Decoder</code>(解码机)的组合，GAN为<code>Generator</code>(生成机)和<code>Discriminator</code>(判别机)的组合，可以认为后者GAN偏向于一个自带数据增强的预测模型。而且在结构上AutoEncoder把两个子结构合二为一一并使用，以最后输出的图像尽可能还原输入的图像为目标，隐层的节点数先逐渐递减再逐渐增加，因此AutoEncoder经常被用于降维任务；而GAN则是轮流训练Generator与Discriminator，直到二者达到动态平衡，因此GAN经常被用于数据增强。另外，二者各有缺点，AutoEncoder的容易生成失真，GAN的容易保留噪声。</p>
<p>除了VAE之外AutoEncoder还有Denoising AutoEncoder和Sparse AutoEncoder两个亚种，感兴趣的话可以上网搜一下，但是内容预算有限，在此暂不赘述。</p>
<blockquote>
<p>Keywords:</p>
<ul>
<li>AutoEncoder</li>
<li>VAE</li>
</ul>
<p>…</p>
</blockquote>
<h3 id="AutoEncoder"><a href="#AutoEncoder" class="headerlink" title="AutoEncoder"></a>AutoEncoder</h3><p>我们先从VAE的原型，即AutoEncoder讲起。</p>
<p><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/what_the_autoencoder.jpeg" alt="AutoEncoder...?"></p>
<p><del>这就是AutoEncoder（大误</del></p>
<p>没错，AutoEncoder说穿了无非就是先压缩再解压回去，或者说先降维再升回去，因此朴素AutoEncoder可以用Keras简单刻画如下：</p>
<figure class="highlight py"><figcaption><span>Naive AutoEncoder</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras, keras.backend <span class="keyword">as</span> T</span><br><span class="line">img_shape = (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>,) <span class="keyword">if</span> T.image_data_format() == <span class="string">&quot;channels_first&quot;</span> <span class="keyword">else</span> (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">AutoEncoder = keras.models.Sequential([</span><br><span class="line">    <span class="comment"># Encoder</span></span><br><span class="line">    keras.layers.Flatten(input_shape=img_shape),</span><br><span class="line">    keras.layers.Dense(<span class="number">224</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">28</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">2</span>, activation=<span class="string">&quot;relu&quot;</span>), <span class="comment"># Latent Bottleneck</span></span><br><span class="line">    <span class="comment"># Decoder</span></span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">196</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1024</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">784</span>, activation=<span class="string">&quot;sigmoid&quot;</span>), <span class="comment"># Output</span></span><br><span class="line">    keras.layers.Reshape(img_shape) <span class="comment"># Post-processing</span></span><br><span class="line">    ])</span><br></pre></td></tr></table></figure>
<p>如代码中所示一样，以MNIST为例，输入一张28x28的灰度图像在中间的Bottleneck会被压缩为一个二维矢量，这直接就可以在一个二维平面上把某张图片所在潜在连续空间中的位置表示出来。在学习较大输入数据的时候可以先把大的输入数据压缩为一个较短的低维矢量进行表示，然后学习被压低的这一块“精髓”。如同下面图片的这张图片：</p>
<p><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/autoencoder.jpeg" alt="AutoEncoder"></p>
<h3 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h3><p>既然AutoEncoder这么流弊，那么为什么还要出这么个亚种呢？</p>
<p><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/why_vae.jpeg" alt="Purpose of VAE"></p>
<p>如上图所示，我们拿满月和弦月的图片训练AutoEncoder，对于AutoEncoder而言，在满月编码的点附近的一块邻域内解码出的图片都是与满月类似，在弦月附近的一块领域内解码出的也都与弦月类似。但是如若我们取两个领域正中间的点进行解码，那么可能什么都解不出来。于是我们对解码过程的起手注入随机噪声，这一块噪声的构成方式是由模型学习得到的，且服从于常态分布，使得在两点之间可以解出介于满月与弦月之间的点，从而构造手写数字图片(MNIST)的潜在连续空间。</p>
<p><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/vae.jpeg" alt="Variational AutoEncoder"></p>
<p>这幅图对比了AutoEncoder与VAE。</p>
<h3 id="Code-1"><a href="#Code-1" class="headerlink" title="Code"></a>Code</h3><p>最后我们还是要放一下代码：</p>
<figure class="highlight py"><figcaption><span>Variational AutoEncoder</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env Python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">TensorFlow version: 1.13.1</span></span><br><span class="line"><span class="string">Keras version: 2.3.1</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras, keras.backend <span class="keyword">as</span> T</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">&quot;solarized-light&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Constants</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    IMG_SHAPE = (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>) <span class="keyword">if</span> T.image_data_format() == <span class="string">&quot;channels_first&quot;</span> <span class="keyword">else</span> (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">    NUM_EPOCHES = <span class="number">10</span></span><br><span class="line">    BATCH_SIZE = <span class="number">16</span></span><br><span class="line">    LATENT_DIM = <span class="number">2</span> <span class="comment"># Dimensionality of the latent space: a plane</span></span><br><span class="line">    NUM_DIGITS = <span class="number">15</span>  <span class="comment"># figure with 15x15 digits</span></span><br><span class="line">    DIGIT_SIZE = <span class="number">28</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Loading MNIST Dataset</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line">x_train = x_train.reshape((x_train.shape[<span class="number">0</span>],) + Constants.IMG_SHAPE).astype(<span class="string">&quot;float32&quot;</span>) / <span class="number">255.</span></span><br><span class="line">x_test = x_test.reshape((x_test.shape[<span class="number">0</span>],) + Constants.IMG_SHAPE).astype(<span class="string">&quot;float32&quot;</span>) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Creating &amp; Building Encoder</span></span><br><span class="line">input_img = keras.Input(shape=Constants.IMG_SHAPE)</span><br><span class="line">x = keras.layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)(input_img)</span><br><span class="line">x = keras.layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>, strides=<span class="number">2</span>)(x)</span><br><span class="line">x = keras.layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">x = keras.layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line"></span><br><span class="line">shape_before_flattening = T.int_shape(x)[ <span class="number">1</span> : ]</span><br><span class="line"></span><br><span class="line">x = keras.layers.Flatten()(x)</span><br><span class="line">x = keras.layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line"></span><br><span class="line">z_mean = keras.layers.Dense(Constants.LATENT_DIM)(x)</span><br><span class="line">z_log_var = keras.layers.Dense(Constants.LATENT_DIM)(x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sampling</span>(<span class="params">args</span>):</span></span><br><span class="line">    z_mean, z_log_var = args</span><br><span class="line">    eps = T.random_normal(</span><br><span class="line">        shape = (T.shape(z_mean)[<span class="number">0</span>], Constants.LATENT_DIM),</span><br><span class="line">        mean=<span class="number">0.</span>, stddev=<span class="number">1.</span></span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> z_mean + T.exp(<span class="number">.5</span> * z_log_var) * eps</span><br><span class="line">z = keras.layers.Lambda(sampling)([z_mean, z_log_var])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creating &amp; Building Decoder</span></span><br><span class="line">decoder = keras.Sequential(layers=[</span><br><span class="line">    <span class="comment"># Upsampling to the correct number of units</span></span><br><span class="line">    keras.layers.Dense(np.prod(shape_before_flattening), activation=<span class="string">&quot;relu&quot;</span>, input_shape=T.int_shape(z)[ <span class="number">1</span> : ]),</span><br><span class="line">    <span class="comment"># Reshape into an image of the same shape as before our last `Flatten` layer</span></span><br><span class="line">    keras.layers.Reshape(shape_before_flattening),</span><br><span class="line">    <span class="comment"># We then apply then reverse operation to the initial stack</span></span><br><span class="line">    <span class="comment">#   of convolution layers: a `Conv2DTranspose` layers</span></span><br><span class="line">    <span class="comment">#   with corresponding parameters.</span></span><br><span class="line">    keras.layers.Conv2DTranspose(<span class="number">32</span>, <span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>, strides=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># We end up with a feature map of the same size as the original input.</span></span><br><span class="line">    keras.layers.Conv2D(<span class="number">1</span>, <span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;sigmoid&quot;</span>)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># We then apply it to `z` to recover the decoded `z`.</span></span><br><span class="line">z_decoded = decoder(z)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomVariationalLayer</span>(<span class="params">keras.layers.Layer</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Custom Layer for Computing Loss of VAE...&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">vae_loss</span>(<span class="params">self, x, z_decoded</span>):</span></span><br><span class="line">        x, z_decoded = T.flatten(x), T.flatten(z_decoded)</span><br><span class="line">        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)</span><br><span class="line">        k1_loss = T.mean(<span class="number">1</span> + z_log_var - T.square(z_mean) - T.exp(z_log_var), axis=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> T.mean(xent_loss + (-<span class="number">5e-4</span>) * k1_loss)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Customizing Layer via `call` method&quot;&quot;&quot;</span></span><br><span class="line">        x = inputs[<span class="number">0</span>]</span><br><span class="line">        z_decoded = inputs[<span class="number">1</span>]</span><br><span class="line">        loss = self.vae_loss(x, z_decoded)</span><br><span class="line">        self.add_loss(loss, inputs=inputs)</span><br><span class="line">        <span class="comment"># We don&#x27;t use this output.</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># We call our custom layer on the input and the decoded output,</span></span><br><span class="line"><span class="comment">#   in order to obtain the final model output.</span></span><br><span class="line">y = CustomVariationalLayer()([input_img, z_decoded])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">vae = keras.models.Model(input_img, y)</span><br><span class="line">vae.<span class="built_in">compile</span>(</span><br><span class="line">    keras.optimizers.RMSprop(),</span><br><span class="line">    loss=<span class="literal">None</span></span><br><span class="line">    )</span><br><span class="line">history = vae.fit(</span><br><span class="line">    x_train, <span class="literal">None</span>,</span><br><span class="line">    batch_size = Constants.BATCH_SIZE,</span><br><span class="line">    epochs = Constants.NUM_EPOCHES,</span><br><span class="line">    validation_data = (x_test, <span class="literal">None</span>),</span><br><span class="line">    shuffle = <span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Displaying a 2D manifold of the digits</span></span><br><span class="line">figure = np.zeros((Constants.DIGIT_SIZE * Constants.NUM_DIGITS, Constants.DIGIT_SIZE * Constants.NUM_DIGITS))</span><br><span class="line"><span class="comment"># Linearly spaced coordinates on the unit square were transformed</span></span><br><span class="line"><span class="comment">#   through the inverse CDF (ppf) of the Gaussian</span></span><br><span class="line"><span class="comment">#   to produce values of the latent variables z,</span></span><br><span class="line"><span class="comment">#   since the prior of the latent space is Gaussian</span></span><br><span class="line">grid_x = norm.ppf(np.linspace(<span class="number">0.05</span>, <span class="number">0.95</span>, Constants.NUM_DIGITS))</span><br><span class="line">grid_y = norm.ppf(np.linspace(<span class="number">0.05</span>, <span class="number">0.95</span>, Constants.NUM_DIGITS))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, yi <span class="keyword">in</span> <span class="built_in">enumerate</span>(grid_x):</span><br><span class="line">    <span class="keyword">for</span> j, xi <span class="keyword">in</span> <span class="built_in">enumerate</span>(grid_y):</span><br><span class="line">        z_sample = np.array([[xi, yi]])</span><br><span class="line">        z_sample = np.tile(z_sample, Constants.BATCH_SIZE).reshape(Constants.BATCH_SIZE, <span class="number">2</span>)</span><br><span class="line">        x_decoded = decoder.predict(z_sample, batch_size=Constants.BATCH_SIZE)</span><br><span class="line">        digit = x_decoded[<span class="number">0</span>].reshape(Constants.DIGIT_SIZE, Constants.DIGIT_SIZE)</span><br><span class="line">        figure[i * Constants.DIGIT_SIZE: (i + <span class="number">1</span>) * Constants.DIGIT_SIZE,</span><br><span class="line">               j * Constants.DIGIT_SIZE: (j + <span class="number">1</span>) * Constants.DIGIT_SIZE] = digit</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">plt.imshow(figure, cmap=<span class="string">&quot;hot&quot;</span>)</span><br><span class="line">plt.imsave(<span class="string">&quot;./result.%s.jpeg&quot;</span> % time.time(), figure, cmap=<span class="string">&quot;hot&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><p>从2019年4月开始尝试到现在，这个project大概持续了一年半，重构程式的时候非常顺利，所以也没什么令人惊喜之感。</p>
<p><img src="/next-nest/2020/11/06/past_posts/essays/2020-1106/vae_result.jpeg" alt="VAE Result"></p>
<h2 id="Summary-2"><a href="#Summary-2" class="headerlink" title="Summary"></a>Summary</h2><!--
$$ A

= \left| \begin{matrix}
a_1    &        &        & \cdots &        \\
       & a_2    &        & \cdots &        \\
       &        & a_3    & \cdots &        \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
       &        &        & \cdots & a_n    \\
\end{matrix} \right|

= a_1 \cdot a_2 \cdot a_3 \cdots a_n

= \prod_{i=1}^n a_i $$

$$ A

= \left| \begin{matrix}
       & \cdots &        &        & a_1    \\
       & \cdots &        & a_2    &        \\
       & \cdots & a_3    &        &        \\
\vdots & \ddots & \vdots & \vdots & \vdots \\
a_n    & \cdots &        &        &        \\
\end{matrix} \right|

= (-1)^{\frac{n(n-1)}{2}} \cdot a_1 \cdot a_2 \cdot a_3 \cdots a_n

= (-1)^{\frac{n(n-1)}{2}} \prod_{i=1}^n a_i $$
-->
<blockquote><p><em>この空をあの星を 奇跡さえ超えて君の元へ</em><br><em>超越這片天空那顆星星 超越奇蹟穿梭到你身邊</em><br>翔べるよ何処までも 今ならきっと大丈夫<br>不論到何處都展翅翱翔 若是現在肯定沒有問題<br>この歌はこの声は いつも君の隣にある<br>這首歌曲和這份歌聲 一直都存在你身邊<br>届けたい 終わりのない空を翔ける星のメロディ<br>想要傳達 在這無盡的天空飛翔的星之旋律<br>★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡<br>巡り会うこの場所で 君と二人の夜空を見る<br>在相逢的這個地點 與你一起仰望兩人的夜空<br>駆け出して それだけできっと夢は叶うから<br>只要開始向前奔跑 夢想就一定能夠實現<br>この歌をこの声を ずっと忘れないでいてね<br>這首歌曲和這份歌聲 請永遠不要忘記喔<br>届けたい 遥か遠いミライ<br>想要傳達 直到遙遠的未來<br>★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡<br>翔ける<br>飛翔吧<br>★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡<br>翔ける<br>飛翔吧<br>★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡★﹣ ﹦ ≡☆﹣ ﹦ ≡<br>全速力のメロディ<br>全速的旋律</p>
<footer><strong>Divela(feat. 初音MIKU)</strong><cite><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/av24556700/">METEOR (Magical Mirai 2018 Contest Champion)</a></cite></footer></blockquote>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>参考文献：</p>
<h3 id="NST-Neural-Style-Transform"><a href="#NST-Neural-Style-Transform" class="headerlink" title="NST (Neural Style Transform)"></a>NST (Neural Style Transform)</h3><ul>
<li>[1]:  <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1508.06576/">https://arxiv.org/abs/1508.06576/</a></li>
<li>[2]:  <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/9f03b61fdeac">https://www.jianshu.com/p/9f03b61fdeac</a></li>
<li>[3]:  <a target="_blank" rel="noopener" href="https://blog.csdn.net/Cowry5/article/details/81037767">https://blog.csdn.net/Cowry5/article/details/81037767</a></li>
<li>[4]:  <a target="_blank" rel="noopener" href="https://blog.csdn.net/level_code/article/details/94631322">https://blog.csdn.net/level_code/article/details/94631322</a></li>
</ul>
<h3 id="Gram-Matrix"><a href="#Gram-Matrix" class="headerlink" title="Gram Matrix"></a>Gram Matrix</h3><ul>
<li>[5]:  <a target="_blank" rel="noopener" href="https://planetmath.org/grammatrix">https://planetmath.org/grammatrix</a></li>
<li>[6]:  <a target="_blank" rel="noopener" href="https://www.cnblogs.com/yifanrensheng/p/12862174.html">https://www.cnblogs.com/yifanrensheng/p/12862174.html</a></li>
</ul>
<h3 id="L-BFGS-B"><a href="#L-BFGS-B" class="headerlink" title="L-BFGS-B"></a>L-BFGS-B</h3><ul>
<li>[7]:  <a target="_blank" rel="noopener" href="http://sepwww.stanford.edu/data/media/public/docs/sep117/antoine1/paper_html/node6.html">http://sepwww.stanford.edu/data/media/public/docs/sep117/antoine1/paper_html/node6.html</a></li>
<li>[8]:  <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_39445556/article/details/84502260/">https://blog.csdn.net/weixin_39445556/article/details/84502260/</a></li>
<li>[9]:  <a target="_blank" rel="noopener" href="http://users.iems.northwestern.edu/~nocedal/software.html">http://users.iems.northwestern.edu/~nocedal/software.html</a></li>
<li>[10]: <a target="_blank" rel="noopener" href="http://sobereva.com/538/">http://sobereva.com/538/</a></li>
</ul>
<h3 id="AE-AutoEncoder"><a href="#AE-AutoEncoder" class="headerlink" title="AE (AutoEncoder)"></a>AE (AutoEncoder)</h3><ul>
<li>[11]: <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/av15998800/">https://www.bilibili.com/video/av15998800/</a></li>
<li>[12]: <a target="_blank" rel="noopener" href="https://blog.csdn.net/leida_wt/article/details/85052299/">https://blog.csdn.net/leida_wt/article/details/85052299/</a></li>
<li>[13]: <a target="_blank" rel="noopener" href="https://www.alwa.info/2016/Autoencoder-详解.html">https://www.alwa.info/2016/Autoencoder-详解.html</a></li>
<li>[14]: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/yangmang/p/7530463.html">https://www.cnblogs.com/yangmang/p/7530463.html</a></li>
</ul>
<h3 id="divela-meteor"><a href="#divela-meteor" class="headerlink" title="divela - meteor"></a>divela - meteor</h3><ul>
<li>[15]: <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1MW411P7PU/">https://www.bilibili.com/video/BV1MW411P7PU/</a></li>
<li>[16]: <a target="_blank" rel="noopener" href="https://music.163.com/#/song?id=1294899575">https://music.163.com/#/song?id=1294899575</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2019/12/06/past_posts/notes/SimulateAnneal/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2019/12/06/past_posts/notes/SimulateAnneal/" class="post-title-link" itemprop="url">模拟退火学习笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-06 19:21:15" itemprop="dateCreated datePublished" datetime="2019-12-06T19:21:15+08:00">2019-12-06</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2019/12/06/past_posts/notes/SimulateAnneal/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2019/12/06/past_posts/notes/SimulateAnneal/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>模拟退火算法(Simulate Anneal, SA)是一种通用概率演算法, 用来在一个大的搜寻空间内找寻命题的最优解, 该算法由S.Kirkpatrick, C.D.Gelatt和M.P.Vecchi于1983年提出, V.Černý在1985年也独立提出该算法。</p>
<h2 id="I-退火"><a href="#I-退火" class="headerlink" title="I. 退火"></a>I. 退火</h2><p>什么是退火?</p>
<p>我们看看来自百度百科的讲解:</p>
<blockquote>
<p>退火是一种金属热处理工艺, 指的是将金属缓慢加热到一定温度, 保持足够时间, 然后以适宜速度冷却。<br>目的是降低硬度, 改善切削加工性; 降低残余应力, 稳定尺寸, 减少变形与裂纹倾向; 细化晶粒, 调整组织, 消除组织缺陷。<br>准确的说, 退火是一种对材料的热处理工艺, 包括金属材料, 非金属材料。<br>而且新材料的退火目的也与传统金属退火存在异同。</p>
</blockquote>
<p>好吧，其实说白了就是这样的一张图:<img src="/next-nest/2019/12/06/past_posts/notes/SimulateAnneal/anneal.jpeg" alt><strong>千言万语不及一幅图啊!!!</strong></p>
<h2 id="II-原理"><a href="#II-原理" class="headerlink" title="II. 原理"></a>II. 原理</h2><p>既然是模拟退火, 其原理也和金属退火大同小异。</p>
<p>金属退火是让固体缓慢加热趋于无序自由, 再缓慢降温逐渐变得有序, 趋于基态, 此时固体的内能最小; 而SA便是<em>当你爬到一个一个局部最优解的时候, 你突发奇想, 破天荒地往山坡上方爬了爬, 发现远处有一个更优解, 而那便是你梦寐以求的全局最优解。</em></p>
<p>就像这样:<img src="/next-nest/2019/12/06/past_posts/notes/SimulateAnneal/convex.jpeg" alt></p>
<p>你从山坡上的A点顺着梯度(普通优化方案)爬到了局部最低的山谷B点, 这个时候你逆梯度而上, 往右向上爬过了那个小山峰, 来到了最低的山谷C点。</p>
<p>SA在实际使用的过程中, 有一个状态转移准则, 来决定你是否要往右爬, 由一个Metropolis概率来表示:</p>
<script type="math/tex; mode=display">p=\begin{cases}
  {E(x_{new}) < E(x_{old})}, & 1 \\
  {E(x_{new}) > E(x_{old})}, & \exp{(-\frac{E(x_{new})-E(x_{old})}T)}
\end{cases}</script><h2 id="III-应用"><a href="#III-应用" class="headerlink" title="III. 应用"></a>III. 应用</h2><p>事实上SA<del>并没多大卵用</del>有着<strong>极为广泛的应用前景</strong>, 包括:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/TSP/2905216">最短路径问题(TSP)</a></li>
<li>NLP, 也就是所谓自然语言处理中的语义分割(主要是英语)(就是你们说的分词)问题, 但语义分割一般会用<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/隐马尔可夫模型/7932524">隐式马尔可夫模型(HMM)</a>或者条件随机场(CRF)之类的比较成熟的算法, 也不会有人<del>吃饱了撑的</del>用SA。<br><img src="/next-nest/2019/12/06/past_posts/notes/SimulateAnneal/crf.jpeg" alt><br>目前语义分割中盛行的<code>CRF+LSTM</code>语义分割模型</li>
</ul>
<p>(内容参考:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/退火/1039313">https://baike.baidu.com/item/退火/1039313</a></li>
<li><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/模拟退火/8664695">https://baike.baidu.com/item/模拟退火/8664695</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.csdn.net/wfrainn/article/details/80303138/">http://blog.csdn.net/wfrainn/article/details/80303138/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/tychyg/p/5277275.html">https://www.cnblogs.com/tychyg/p/5277275.html</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/ranjiewen/p/6084052.html">https://www.cnblogs.com/ranjiewen/p/6084052.html</a></li>
</ul>
<p>)</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2019/07/18/past_posts/essays/2019-0718/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2019/07/18/past_posts/essays/2019-0718/" class="post-title-link" itemprop="url">日志#2019-0718 XRS集训</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-07-18 22:43:48" itemprop="dateCreated datePublished" datetime="2019-07-18T22:43:48+08:00">2019-07-18</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2019/07/18/past_posts/essays/2019-0718/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2019/07/18/past_posts/essays/2019-0718/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="XRS-数学集训-Day4"><a href="#XRS-数学集训-Day4" class="headerlink" title="XRS 数学集训 Day4"></a>XRS 数学集训 Day4</h1><h3 id="2019年7月18日"><a href="#2019年7月18日" class="headerlink" title="2019年7月18日"></a>2019年7月18日</h3><p>杨水大学四年差不多是白学了，竟然把 $\sigma$ (Sigma)读成了 $\epsilon$ (Epsilon)。</p>
<p>今天下了不小的雨，虽说是阵雨也还是引起了不小的紧张气氛，杨冰还格外殷勤地关心我们是否有带上之类的。</p>
<p><strong>Day4结束了椭圆的学习，明天开双曲线和抛物线。</strong>课后测不知为何难得一批，做起来也难受得一批。全班上下没有全对的，杨水决定奖励仅错了一道题的两位学神——于宜萌和刁文昊——帮他们分别实现一个愿望，然而前者许愿要100个愿望，后者想要帮忙氪金648.。。</p>
<p>好吧，我自己做得差得一批，错了三道题目，两道计算错一道审错题。</p>

    <div id="aplayer-TwtRSDBR" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="33223391" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#ad7a86"></div>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2019/07/17/past_posts/essays/2019-0717/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2019/07/17/past_posts/essays/2019-0717/" class="post-title-link" itemprop="url">日志#2019-0717 XRS集训</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-07-17 22:15:47" itemprop="dateCreated datePublished" datetime="2019-07-17T22:15:47+08:00">2019-07-17</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2019/07/17/past_posts/essays/2019-0717/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2019/07/17/past_posts/essays/2019-0717/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="XRS-数学集训-Day3"><a href="#XRS-数学集训-Day3" class="headerlink" title="XRS 数学集训 Day3"></a>XRS 数学集训 Day3</h1><h3 id="2019年7月17日"><a href="#2019年7月17日" class="headerlink" title="2019年7月17日"></a>2019年7月17日</h3><p>杨水：我虽然只有18岁，但我比较内向，我的内心住着一只小公举。<br>蒸鹅心</p>
<p>今天感觉做的还可以，课后测也就一道大题最后的数学期望算错了，无伤大雅。</p>
<p><strong>Day3把空间解析几何收尾，主攻概率统计。</strong></p>
<p>明天圆锥曲线怕不是要干爆一批人，可能上来就能把我锤爆，耳边回响起了八爷的《LOSER》。</p>

    <div id="aplayer-qkgBQJcB" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="1324466790" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#ad7a86"></div>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2019/07/16/past_posts/essays/2019-0716/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2019/07/16/past_posts/essays/2019-0716/" class="post-title-link" itemprop="url">日志#2019-0716 XRS集训</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-07-16 22:15:40" itemprop="dateCreated datePublished" datetime="2019-07-16T22:15:40+08:00">2019-07-16</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2019/07/16/past_posts/essays/2019-0716/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2019/07/16/past_posts/essays/2019-0716/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="XRS-数学集训-Day2"><a href="#XRS-数学集训-Day2" class="headerlink" title="XRS 数学集训 Day2"></a>XRS 数学集训 Day2</h1><h3 id="2019年7月16日"><a href="#2019年7月16日" class="headerlink" title="2019年7月16日"></a>2019年7月16日</h3><p>今天早晨到教室的时间跟昨天差不多。</p>
<p><strong>Day2讲的是空间几何和矢量运算（@一方通行）。</strong></p>
<p>好久没做空间几何了，所以一开始在用纯几何方法（不建立空间直角坐标系）的时候做起题来非常吃力，不过做着做着就感觉好些了。</p>
<p>今天我发现是个学神都在玩手机，看来也就是我这样的菜鸡需要学习qaq。</p>
<p>今天上午还是阴天，下午的天气就好多了，令人想到<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/米津玄师/703289">米津玄师</a>的《Lemon》。</p>

    <div id="aplayer-hLwwJGrR" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="573747359" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#ad7a86"></div>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2019/07/15/past_posts/essays/2019-0715/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2019/07/15/past_posts/essays/2019-0715/" class="post-title-link" itemprop="url">日志#2019-0715 XRS集训</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-07-15 22:15:35" itemprop="dateCreated datePublished" datetime="2019-07-15T22:15:35+08:00">2019-07-15</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2019/07/15/past_posts/essays/2019-0715/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2019/07/15/past_posts/essays/2019-0715/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="XRS-数学集训-Day1"><a href="#XRS-数学集训-Day1" class="headerlink" title="XRS 数学集训 Day1"></a>XRS 数学集训 Day1</h1><h3 id="2019年7月15日"><a href="#2019年7月15日" class="headerlink" title="2019年7月15日"></a>2019年7月15日</h3><p>我差不多是在还有30min上课就到达教室了，当时教室里也就七八个人，除了某位学神在玩手机之外其他人都在肝作业。</p>
<p>今天见到了传说之中的刁文昊学神（本尊，说实话和想象中的有些出入）、前两天就见到的辛若沫学神和已有很久没有见到的栾澍学神。</p>
<p><strong>Day1复习的是解三角形和数列，后者包括裂项相消和差位相减。</strong></p>
<p>课后测该死地错了一大坨，真的是好久没复习这块内容了，加之一开始学的也不太好，所以做得很萎貌似可以预料。</p>
<p>（我们安利杨水去听了《鸡你太美》（有一个著名的翻唱叫《只因你太美》），然后他就开始在我们班疯狂地播放这首歌。）</p>

    <div id="aplayer-IncABSig" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="1358620636" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#ad7a86"></div>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liella-gen2.github.io/next-nest/2019/06/13/past_posts/notes/Dler-Skills/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
      <meta itemprop="name" content="世界ノ敵P">
      <meta itemprop="description" content="欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Next Nest">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/next-nest/2019/06/13/past_posts/notes/Dler-Skills/" class="post-title-link" itemprop="url">浅谈深度学习技能栈</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-06-13 08:36:36" itemprop="dateCreated datePublished" datetime="2019-06-13T08:36:36+08:00">2019-06-13</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/next-nest/2019/06/13/past_posts/notes/Dler-Skills/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/next-nest/2019/06/13/past_posts/notes/Dler-Skills/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>(文章参考 <a target="_blank" rel="noopener" href="https://hongbomin.com/2017/02/17/deep-learner/">https://hongbomin.com/2017/02/17/deep-learner/</a> ，感谢<strong>洪柏敏</strong>dalao的指点)</p>
<p>借用一下参考文章的开头：</p>
<blockquote>
<p>深度学习，自2012年以来，一年比一年火。相比80年代的人工智能热，这一次，基于深度学习的各种智能服务确实带来了可见的惊喜。<br>深度学习在图像领域的各层面都取得了骄人的成绩，包括分割、识别等高级任务，以及去噪、二值化、超分辨率等低级任务。<br>在语音以及自然语言处理等方面也在快速发展。</p>
</blockquote>
<p>是的没错，这个领域有着不可估量的发展空间与前途，在未来有着各种各样的应用。</p>
<p>所以我们今天来谈一谈深度学习所需要掌握的各项技能，先从最基本的谈起：</p>
<h2 id="基础设施"><a href="#基础设施" class="headerlink" title="基础设施"></a>基础设施</h2><h3 id="计算机语言"><a href="#计算机语言" class="headerlink" title="计算机语言"></a>计算机语言</h3><ul>
<li>Python <a target="_blank" rel="noopener" href="https://www.python.org/">https://www.python.org/</a></li>
<li>R <a target="_blank" rel="noopener" href="https://www.r-project.org/">https://www.r-project.org/</a></li>
<li>Anaconda (一种科学计算用Python发行版，自带R的集成开发环境RStudio和Python机器学习需要用到的诸多模块如NumPy) <a target="_blank" rel="noopener" href="https://www.anaconda.com/">https://www.anaconda.com/</a></li>
</ul>
<h3 id="朴素机器学习框架-based-on-Python"><a href="#朴素机器学习框架-based-on-Python" class="headerlink" title="朴素机器学习框架 (based on Python)"></a>朴素机器学习框架 (based on Python)</h3><ul>
<li>NumPy (Python数值代数模块) <a target="_blank" rel="noopener" href="https://www.numpy.org/">https://www.numpy.org/</a><ul>
<li>中文文档 <a target="_blank" rel="noopener" href="https://www.numpy.org.cn/">https://www.numpy.org.cn/</a></li>
</ul>
</li>
<li>SciPy (Python科学计算模块) <a target="_blank" rel="noopener" href="https://www.scipy.org/">https://www.scipy.org/</a></li>
<li>SymPy (Python符号计算模块) <a target="_blank" rel="noopener" href="https://www.sympy.org/zh/">https://www.sympy.org/zh/</a></li>
<li>Pandas (Python数据存储模块) <a target="_blank" rel="noopener" href="http://pandas.pydata.org/">http://pandas.pydata.org/</a><ul>
<li>中文文档 <a target="_blank" rel="noopener" href="https://www.pypandas.cn/">https://www.pypandas.cn/</a></li>
</ul>
</li>
<li>Matplotlib (Python数据可视化模块) <a target="_blank" rel="noopener" href="https://matplotlib.org/">https://matplotlib.org/</a><ul>
<li>中文文档 <a target="_blank" rel="noopener" href="https://www.matplotlib.org.cn/">https://www.matplotlib.org.cn/</a></li>
</ul>
</li>
</ul>
<h3 id="深度学习框架-based-on-Python"><a href="#深度学习框架-based-on-Python" class="headerlink" title="深度学习框架 (based on Python)"></a>深度学习框架 (based on Python)</h3><ul>
<li>Theano <a target="_blank" rel="noopener" href="https://deeplearning.net/software/theano/">https://deeplearning.net/software/theano/</a></li>
<li>TensorFlow <a target="_blank" rel="noopener" href="https://tensorflow.org/">https://tensorflow.org/</a><ul>
<li>中文站点 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/">https://tensorflow.google.cn/</a></li>
<li>中文社区 <a target="_blank" rel="noopener" href="http://www.tensorfly.cn/">http://www.tensorfly.cn/</a></li>
<li>试用Playground <a target="_blank" rel="noopener" href="https://playground.tensorflow.org/">https://playground.tensorflow.org/</a></li>
</ul>
</li>
<li>CNTK <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/cognitive-toolkit/">https://docs.microsoft.com/en-us/cognitive-toolkit/</a></li>
<li>Keras <a target="_blank" rel="noopener" href="https://keras.io/zh/">https://keras.io/zh/</a></li>
</ul>
<h2 id="数学基础"><a href="#数学基础" class="headerlink" title="数学基础"></a>数学基础</h2><ul>
<li>微积分/高等数学/数学分析</li>
<li>线性代数</li>
<li>统计学基础, 包括以下三者:<ul>
<li>概率论</li>
<li>信息论</li>
<li>数理统计</li>
</ul>
</li>
<li>数值代数(主要指的是数值计算方法与数学建模方法等)</li>
</ul>
<h2 id="朴素机器学习方法"><a href="#朴素机器学习方法" class="headerlink" title="朴素机器学习方法"></a>朴素机器学习方法</h2><h3 id="常用框架"><a href="#常用框架" class="headerlink" title="常用框架"></a>常用框架</h3><ul>
<li>Scikit-Learn <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/">https://scikit-learn.org/stable/</a></li>
</ul>
<h3 id="基础算法"><a href="#基础算法" class="headerlink" title="基础算法"></a>基础算法</h3><ul>
<li>分类 Classification<ul>
<li>逻辑回归 Logistic Regression (没错它一个分类算法名字叫回归)</li>
</ul>
</li>
<li>回归 Regression<ul>
<li>线性回归算法<ul>
<li>基于 最小二乘法/最小平方法 的线性回归 Linear Regression</li>
<li>岭回归/脊回归 Ridge Regression</li>
<li>套索回归 Lasso Regression</li>
<li>弹性网络回归 Elastic-Net Regression</li>
</ul>
</li>
<li>贝叶斯回归 Bayesian Regression</li>
</ul>
</li>
<li>分类&amp;回归(可以同时用于两者的算法)<ul>
<li>判别分析 Discriminant Analysis<ul>
<li>线性判别分析/Fisher判别分析 Linear Discriminant Analysis (LDA)</li>
<li>二次判别分析 Quadratic Discriminant Analysis (QDA)</li>
</ul>
</li>
<li>K最近邻 K-Nearest Neighbor (kNN)</li>
<li>高斯过程 Gaussian Processes (GP)</li>
<li>朴素贝叶斯 Naive Bayes (NB)</li>
<li>决策树 Decision Trees (DT/CART)</li>
<li>支持矢量机 Support Vector Machines (SVM)</li>
</ul>
</li>
</ul>
<h3 id="高阶算法"><a href="#高阶算法" class="headerlink" title="高阶算法"></a>高阶算法</h3><ul>
<li>聚类 Clustering<ul>
<li>K均值 K-Means</li>
<li>均值漂移 Mean Shift</li>
<li>DBSCAN</li>
</ul>
</li>
<li>降维 Dimensionality Reduction<ul>
<li>主成分分析 Principal Component Analysis (PCA)</li>
</ul>
</li>
</ul>
<hr>
<p>接下来要迈入深度学习的世界了</p>
<h2 id="几大深度学习课题"><a href="#几大深度学习课题" class="headerlink" title="几大深度学习课题"></a>几大深度学习课题</h2><ul>
<li>计算机视觉 Computer Vision</li>
<li>自然语言处理 Natural Language Processing (NLP)</li>
<li>语音识别 Voice Recognition</li>
</ul>
<p>以及更多…</p>
<h2 id="经典模型"><a href="#经典模型" class="headerlink" title="经典模型"></a>经典模型</h2><h3 id="卷积神经网络-Convolutional-Neural-Networks-CNN"><a href="#卷积神经网络-Convolutional-Neural-Networks-CNN" class="headerlink" title="卷积神经网络 Convolutional Neural Networks (CNN)"></a>卷积神经网络 Convolutional Neural Networks (CNN)</h3><ul>
<li>LeNet-5 <a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/lenet/a35.html">http://yann.lecun.com/exdb/lenet/a35.html</a></li>
<li>VGG-Net (Visual Geometry Group Network) <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/VGG%20模型">https://baike.baidu.com/item/VGG%20模型</a></li>
<li>GoogLeNet <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/GoogLeNet">https://baike.baidu.com/item/GoogLeNet</a></li>
</ul>
<h3 id="循环神经网络-Recurrent-Neural-Network-RNN"><a href="#循环神经网络-Recurrent-Neural-Network-RNN" class="headerlink" title="循环神经网络 Recurrent Neural Network (RNN)"></a>循环神经网络 Recurrent Neural Network (RNN)</h3><ul>
<li>SimpleRNN</li>
<li>LSTM (Long Short-Term Memory, 长短期记忆网络) <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/LSTM">https://baike.baidu.com/item/LSTM</a></li>
<li>GRU</li>
</ul>
<h3 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h3><ul>
<li>R-CNN</li>
<li>YOLO (You Only Look Once)</li>
</ul>
<h3 id="生成式深度学习"><a href="#生成式深度学习" class="headerlink" title="生成式深度学习"></a>生成式深度学习</h3><ul>
<li>AE (Auto Encoder, 自动编码机)</li>
<li>RBM (Restricted Boltzmann Machine, 受限玻尔兹曼机)</li>
<li>DBN (Deep Belief Network, 深度信念网络)</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/next-nest/page/4/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/next-nest/">1</a><span class="space">&hellip;</span><a class="page-number" href="/next-nest/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/next-nest/page/6/">6</a><a class="page-number" href="/next-nest/page/7/">7</a><a class="extend next" rel="next" href="/next-nest/page/6/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="世界ノ敵P"
      src="https://p1.music.126.net/XYqXjtkrAAQ5IUzFN_Hwqg==/109951164137145524.jpg">
  <p class="site-author-name" itemprop="name">世界ノ敵P</p>
  <div class="site-description" itemprop="description">欲しがったものは全部無くなって消えてくけど<br />生きていく理由は　きっとこれからでも見つかるよ</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/next-nest/archives/">
        
          <span class="site-state-item-count">65</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/next-nest/tags/">
          
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/sandyzikun/" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;sandyzikun&#x2F;" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner footer-banner">
        <h1>Sharing the World!!</h1>
      </div>
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">世界ノ敵P</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/next-nest/lib/anime.min.js"></script>
  <script src="/next-nest/lib/velocity/velocity.min.js"></script>
  <script src="/next-nest/lib/velocity/velocity.ui.min.js"></script>

<script src="/next-nest/js/utils.js"></script>

<script src="/next-nest/js/motion.js"></script>


<script src="/next-nest/js/schemes/pisces.js"></script>


<script src="/next-nest/js/next-boot.js"></script>




  




  
<script src="/next-nest/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'BJvasWrnRIBUV00qcgQGbLKo-gzGzoHsz',
      appKey     : 'MojnnrK48CIUxLurDH2W3uj9',
      placeholder: "Just tell and share your feelings...",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

<script src="/next-nest/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/next-nest/live2dw/assets/miku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
